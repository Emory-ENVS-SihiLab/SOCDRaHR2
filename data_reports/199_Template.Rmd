---
title: 'ISCN 3_1'
author: 'Dr. Katherine Todd-Brown, Julie Bielecki, Anne Davin, Rita Hippe, Urmi Thorat'
date: '5/25/2021'
output: html_document
---

# Introduction

International Soil Carbon Network 3 (ISCN3) consists of serveral data sets. This R Markdown cleans and reorganizes ISCN3 datasets into a study level table, a profile level table, and a layer level table using the ISCN3_1 function. Additionally, maps for each data set are produced within this R Markdown.

The `study` table produced by the ISCN3_1 function describe information about each data contribution including any citations practices and contact information for the contributor. The `profile` table produced by the ISCN3_1 function describes core summary information that is 2D resolved.In contrast, the `layer` table produced the ISCN3_1 function holds 3D resolved information.


```{r warning=FALSE, message=FALSE}
library(data.table)
library(SOCDRaH2)
library(tidyverse)
library(lubridate)
library(tibble)
library(ggmap)
library(maps)
library(mapdata)
library(knitr)
library(tidyr)

data_dir <- '../ISCN3'

ISCN3 <- ISCN3_1(data_dir)
```


```{r message=FALSE, warning=FALSE}
knitr::kable(t(dataset_study))
```


There are the following factors in the profile:

```{r}
knitr::kable(summary(dataset_profile %>% select_if(is.factor)))
```

And the following factors in the layers:
```{r}
knitr::kable(summary(dataset_layer %>% select_if(is.factor)))
```


## Location
```{r}
ggplot(data =  map_data('world')) + 
  geom_polygon(aes(x=long, y = lat, group = group), 
               fill = 'grey', color = 'black') + 
  geom_point(data= dataset_profile, 
             aes(x = `long (dec. deg)`, y = `lat (dec. deg)`),
             shape = 'x', color = 'red') +
  coord_fixed(1.3) +
  theme_nothing() +
  labs(title = 'Profile data') #+
#coord_map('ortho', orientation = c(90, 0, 0))
ggplot(data =  map_data('world')) + 
  geom_polygon(aes(x=long, y = lat, group = group), 
               fill = 'grey', color = 'black') + 
  geom_point(data= dataset_layer %>% select(`long (dec. deg)`, `lat (dec. deg)`) %>% unique(), 
             aes(x = `long (dec. deg)`, y = `lat (dec. deg)`),
             shape = 'x', color = 'red') +
  coord_fixed(1.3) +
  theme_nothing() +
  labs(title = 'Layer data')
```


## Use if map is not centered around the specific region of dataset
```{r}
#country <- ggplot2::map_data('world2', 'usa')
#avgLat <- dataset_layer %>% 
#  pull('lat (dec. deg)') %>%
#  mean()
#avgLong <- dataset_layer %>% 
#  pull('long (dec. deg)') %>%
#  mean() + 360
#ggplot(data =  map_data('world2')) +
#  geom_polygon( aes(x = long, y = lat, group = group),
#                fill = 'grey', color = 'black') +
#  geom_polygon(data = country, aes(x = long, y = lat, group = group),
#                fill = 'lightblue', color = 'black') +
#  geom_point(data = dataset_profile, aes(x = avgLong, y = avgLat), shape = 'x', color = 'red', size = 5) +
#  coord_cartesian(xlim=c(avgLong - 65, avgLong + 65), ylim = c(avgLat - 25, avgLat + 25)) +
#  theme_nothing() +
#  labs(title = 'Profile data')
#ggplot(data =  map_data('world2')) + 
#  geom_polygon(aes(x=long, y = lat, group = group), 
#               fill = 'grey', color = 'black') + 
#  geom_polygon(data = country, aes(x = long, y = lat, group = group),
#                fill = 'lightblue', color = 'black') +
#  geom_point(data = dataset_layer, aes(x = `long (dec. deg)` + 360, y = `lat (dec. deg)`),
#             shape = 'x', color = 'red', size = 2.5) +
#  coord_cartesian(xlim=c(avgLong - 9.1, avgLong + 9.1), ylim = c(avgLat - 3.5, avgLat + 3.5)) +
#  theme_nothing() +
#  labs(title = 'Layer data')

```

```{r eval=FALSE}
#this is useful to see for the analysis but we don't want it in the report
dataset_layer %>%
  pivot_longer(cols = intersect(names(.), type_cols$num_cols), values_drop_na = TRUE) %>%
  group_by(name) %>% summarize(n = length(value), unique_n = length(unique(value))) %>%
  bind_rows(
    dataset_layer %>%
      pivot_longer(cols = intersect(names(.), type_cols$factor_cols), values_drop_na = TRUE) %>%
      group_by(name) %>% summarize(n = length(value), unique_n = length(unique(value))) ) %>%
  arrange(n) %>%
  knitr::kable()
```

## Profile histograms

```{r}
ggplot(dataset_profile %>%
         pivot_longer(cols = intersect(names(.), type_cols$num_cols), 
                      values_to = 'measurement', names_to = 'type')) +
  geom_histogram(aes(x=measurement)) +
  facet_wrap(~type, scales='free') +
  theme_bw()
```

## Depth plots

```{r}
ggplot(dataset_layer %>% 
         pivot_longer(cols=c('layer_top (cm)', 'layer_bot (cm)'),
                      values_to='depth') %>%
         pivot_longer(cols = intersect(names(.), type_cols$num_cols), 
                      values_to = 'measurement', names_to = 'type')) +
  geom_line(aes(x=depth, y= measurement, group = profile_name), alpha = 0.5) +
  facet_wrap(~type, scales='free') +
  theme_bw()
```


## Individualized tables, maps, histograms, and depth plots by dataset



## Plot-generating function 
```{r}

plotGenerate <- function(ISCN3, datasetName) {
  #### VARIABLE INITIALIZATION ####
  
  # filtering ISCN3 for the specific dataset's information
  datasetStudy <- ISCN3$study %>%
                  filter(dataset_name == datasetName)
  datasetProfile <- ISCN3$profile %>%
                    filter(dataset_name_sub == datasetName)
  datasetLayer <- ISCN3$layer %>%
                  filter(dataset_name_sub == datasetName)
  profileCheck <- nrow(datasetProfile) # checking if profile table is empty
  
  # setting extra blanks in knitr tables to print as a space
  options(knitr.kable.NA = '')   
  
  # if no profile data, printing this message in place of profile table
  profileTable <- paste('[',
                        datasetName,  # printing specific dataset's name
                        '] does not contain profile data.', sep = '')
  # setting as NA in case the dataset does not have profile data
  profileMap <- NA
  histograms <- NA
  
  # removing NA values for later plotting
  datasetProfileRemNA <- datasetProfile %>%
                          dplyr::select(where(function(xx) {!all(is.na(xx))}))
  datasetLayerRemNA <- datasetLayer %>%
                          dplyr::select(where(function(xx) {!all(is.na(xx))}))
  
  
  
  #### SUMMARY TABLES ####  
  
  studyTable <- knitr::kable(t(datasetStudy %>%
                         dplyr::select(where(function(xx) {!all(is.na(xx))}))),
                         col.names = '',
                         caption = paste('A summary of [', datasetName,
                                   '] study and contact information.',
                                   sep = ''))
  
  # checking for existence of profile data before creating table
  if(profileCheck != 0) {
    profileTable <- knitr::kable(summary(datasetProfileRemNA %>%
                       select_if(is.factor) %>%
                       mutate_all(droplevels)),
             caption = paste('A summary of [', datasetName,
                       '] profile data,  \nwhich is 2D resolved information.',
                       sep = ''))
  } else {} # keeping profileTable as NA
  
  layerTable <- knitr::kable(summary(datasetLayerRemNA %>%
                       select_if(is.factor) %>%
                       mutate_all(droplevels)),
             caption = paste('A summary of [', datasetName,
                       '] layer data,  \ncontaining 3D resolved information.',
                       sep = ''))

  
  
  #### MAPPING VARIABLES ####
  
  # can shift y-coordinate 360 degrees into the correct orientation if needed
  shift360 <- 0   # usually only needed for ggplot's 'world2' map
  # hard-coding borders to Alaska maps
  alaskaCoords <- list(coord_cartesian(xlim = c(184.6,231.4),
                                       ylim = c(53,71)))
  
  # dataset's country(s) to later see if a world map is needed
  datasetCountry <- unique(datasetLayer %>% select(`country (country)`))
  # dataset's state (to use in state-specific mapping)
  datasetState <- unique(datasetLayer$`state (state_province)`)
  # formatting dataset's state to match that in ggplot map data
  mapStateData <- map_data('state') %>% 
                  filter(region %in% tolower(datasetState))
  
  
  # generic mapping code to build off of or modify with other ggplot arguments
  ggMapBase <- list(geom_polygon(aes(x=long, y = lat, group = group), 
                                 fill = 'grey', color = 'black'),
                    coord_fixed(1.3),   # scaling map proportionally
                    xlab('Longitude'), ylab('Latitude'))
  
  # coloring all of the US light blue
  ggUSAFillBlue <- geom_polygon(data = ggplot2::map_data('world2', 'usa'),
                                     aes(x = long, y = lat, group = group),
                                     fill = 'lightblue', color = 'black')
  
  # only coloring the dataset's state blue
  ggStateFillBlue <- geom_polygon(data = mapStateData,
                      aes(x=long, y = lat, group = group),
                      fill = 'light blue', color = 'black')
  
  # creating variables to easily call the correct title and captions for maps
  mapTitleProfile <- labs(title = 'Profile Data Map',
       caption = paste('A map of [', datasetName,
       '] sampling sites,  \nusing coordinates found within the profile data.',
       sep = ''))
  mapTitleLayer <- labs(title = 'Layer Data Map',
         caption = paste('A map of [', datasetName,
         '] sampling sites,  \nusing coordinates found within the layer data.',
         sep = ''))
  
  # Variables for auto-scaling map
    # creating easier reference for latitudes
  baseLat <- datasetProfile %>%
              dplyr::pull('lat (dec. deg)')
    # doing same for longitudes - will be used in creating map boundaries
  baseLong <- datasetProfile %>%
              dplyr::pull('long (dec. deg)') 
  
  # checking if range of longitudes is <= 10 (as they showed more variation), 
  if(diff(range(baseLong, na.rm = TRUE)) <= 10) {
    # multiplying by a larger number to make map more zoomed in
    rangeLat <- diff(range(baseLong, na.rm = TRUE)) * 12
  } else {
    # since range of coordinates is larger, does not to be as zoomed in
    rangeLat <- diff(range(baseLong, na.rm = TRUE)) * 8
  }
  
 # scaling the map so that longitude:latitude ratio creates a proportional map
  calcLat <- rangeLat * 2.6
  
  # creating new map limits based on the range of coordinates
  adjustedCoords <- coord_cartesian(  # shifting 360 degrees for 'world2' map
                        xlim = c(mean(baseLong, na.rm = TRUE) + 360 - calcLat,
                                 mean(baseLong, na.rm = TRUE) + 360 + calcLat),
                        ylim = c(mean(baseLat, na.rm = TRUE) - rangeLat,
                                 mean(baseLat, na.rm = TRUE) + rangeLat))
  
  
  
  
  #### PROFILE MAP ####
  
  # initializing profile-specific map variables
  datasetInfo <- datasetProfile   # setting profile data to be used for mapping
  
  # variable that will put a red X for each site on profile map
  ggRedX <- geom_point(data= datasetInfo, 
                       aes(x = `long (dec. deg)` +
                             shift360,   # shifting 0 unless specified to 360
                           y = `lat (dec. deg)`),
                       shape = 'x', color = 'red', size = 3)
  
  # PROFILE MAP GENERATION
  # checking for existence of profile data
  if(profileCheck != 0) {
    # checking if dataset has data in more than one country
    if(nrow(unique(datasetProfile %>%  select(`country (country)`))) > 1 ) {
      # using world map to show multiple countries
      profileMap <- ggplot(data =  map_data('world')) +
        ggMapBase + ggRedX + 
        mapTitleProfile
    } else if(datasetCountry ==  'United States') {
      # checking if in Alaska, since is at least in US
      if(datasetState == 'Alaska') {
        # shifting coordinates 360 degrees to correct orientation for 'world2'
        shift360 <- 360
        
        profileMap <- ggplot(data =  map_data('world2')) +
          ggMapBase + ggUSAFillBlue +  # highlights US in light blue 
          ggRedX + alaskaCoords +  # using hard-coded Alaska map boundaries
          mapTitleProfile
      } else {
        # mapping for any other US state
        profileMap <- ggplot(data =  map_data('state')) + # continental US map
          ggMapBase + ggStateFillBlue +  # colors state of interest with blue
          ggRedX + mapTitleProfile  
      }
    } else { # use auto-scaling map code (if not in US)
      shift360 <-  360   # shifting longitude variables 360 degrees
      
      profileMap <- ggplot(data =  map_data('world2')) +
        ggMapBase + ggRedX +
        adjustedCoords + # map coordinate limits based on longitude range
        mapTitleProfile 
    }
  } else if(datasetCountry ==  'United States' & datasetState != 'Alaska') {
    # highlighting state that layer data is located when no profile data
    profileMap <- ggplot(data =  map_data('state')) +
      ggMapBase + ggStateFillBlue +
      labs(title = 'Highlighted Layer Data Map',
           caption = paste('A U.S. map of where [', datasetName,
                      '] sampling occured,  \nusing layer information
                      since this dataset does not have profile information.',
                      sep = ''))
  } else {}   # keeping profileMap as NA
  
  
  
  #### LAYER MAP ####
  
  # initializing profile-specific map variables
  datasetInfo <- datasetLayerRemNA %>%    # now setting layer data for mapping
                  select(`long (dec. deg)`, `lat (dec. deg)`) %>%
                  unique() # removing duplicate sites
  
  # updating red X code with layer data
  ggRedX <- list(geom_point(data= datasetInfo, 
                            aes(x = `long (dec. deg)` + shift360,
                                y = `lat (dec. deg)`),
                            shape = 'x', color = 'red', size = 3))
  
  # LAYER MAP GENERATION
  # checking if layer data is in more than one country
  if(nrow(datasetCountry) > 1 ) {
    # using world map to show multiple countries
    layerMap <-ggplot(data =  map_data('world')) +
      ggMapBase + ggRedX +
      mapTitleLayer    
  } else if(datasetCountry ==  'United States' &  # testing for continental US
            na.omit(datasetState) != 'Alaska') {
    # continental US mapping 
    layerMap <- ggplot(data =  mapStateData) +  # mapping with dataset's state
      ggMapBase + ggStateFillBlue +
      ggRedX + mapTitleLayer
  } else {
    # shifting coordinate system because of shift in 'world2' map
    shift360 <- 360     
    
  layerMap <- ggplot(data =  map_data('world2')) +
    ggMapBase + ggUSAFillBlue + ggRedX +  # highlighting US
    alaskaCoords +   # Alaska-specific map boundaries
    mapTitleLayer
  }
  
  
  
  #### PLOTS ####    
  
  # checking if dataset has profile data
  if(profileCheck != 0) {
    histograms <-  ggplot(datasetProfileRemNA %>%
              # plotting columns shared by num_cols and dataset's profile data
                pivot_longer(cols =  intersect(names(.),
                                               ISCN3$type_columns$num_cols),
                             # setting axes
                             values_to = 'measurement', 
                             names_to = 'type')) +
              geom_histogram(aes(x=measurement)) + # creating histogram
              facet_wrap(~type, scales='free') + # automatically scaling
              labs(title = 'Profile Value Histograms',
                   caption = paste('Histograms detailing measurements in [',
                                   datasetName, '] profile data.',
                                   sep = ''))
  } else {}
  # creating a line graph to show different measurements by depth
  depthPlots <- ggplot(datasetLayerRemNA %>% 
                 # setting which columns to make x-axis
                 pivot_longer(cols=c('layer_top (cm)',
                                     'layer_bot (cm)'),
                              values_to='depth') %>%
                 # setting which measurements to include for each chart/y-axis
                 pivot_longer(cols = intersect(names(.),
                                     ISCN3$type_columns$num_cols), 
                              values_to = 'measurement',
                              names_to = 'type')) +
                # adding line to connect data points
                geom_line(aes(x=depth, y= measurement, group = profile_name),
                          alpha = 0.5) +
                facet_wrap(~type, scales='free') + # automatic scaling
                labs(title = 'Layer Data Depth Plots',
                     caption = paste('Plots of [', datasetName,
                                     '] layer data by depth.', sep = ''))
  
  theme_set(theme_grey())  #setting ggplot theme
  
  #### RETURN ####   
  return(list(summaryStudyTable = studyTable,
              profileTable = profileTable,
              layerTable = layerTable,
              profileMap = profileMap,
              layerMap = layerMap,
              profileValueHistograms = histograms,
              depthValuePlots = depthPlots))  
}

#$Visuals <- plotGenerate(ISCN3, datasetName = 'Heckman lithosequence')
#Visuals <- plotGenerate(ISCN3, datasetName = 'Bockheim')
#Visuals <- plotGenerate(ISCN3, datasetName = 'Jorgensen_NPS')
#Visuals <- plotGenerate(ISCN3, datasetName = 'Worldwide soil carbon and nitrogen data')
#Visuals <- plotGenerate(ISCN3, datasetName = 'UMBS_FASET')
Visuals <- plotGenerate(ISCN3, datasetName = 'NRCS')

#Visuals <- plotGenerate(ISCN3, datasetName = 'Oak Ridge National Lab_TDE')  #all have same lat and lon ??

print(Visuals)

```

## Heckman/Swanston Biscuit Burn
```{r}
plotGenerate(ISCN3, datasetName = 'Heckman/Swanston Biscuit Burn')
```

## Lu_PIMA
```{r}
plotGenerate(ISCN3, datasetName = 'Lu_PIMA')
```

## Heckman lithosequence
```{r} 
plotGenerate(ISCN3, datasetName = 'Heckman lithosequence')
```

## Oak Ridge National Lab_Loblolly_DWJ
```{r} 
plotGenerate(ISCN3, datasetName = 'Oak Ridge National Lab_Loblolly_DWJ')
```

## Lu_LTER
```{r} 
plotGenerate(ISCN3, datasetName = 'Lu_LTER')
```

## Lehmann Soil C&BC #1
```{r} 
plotGenerate(ISCN3, datasetName = 'Lehmann Soil C&BC #1')
```

## Schuur
```{r} 
plotGenerate(ISCN3, datasetName = 'Schuur')
```

## Lehmann NE US soils
```{r} 
plotGenerate(ISCN3, datasetName = 'Lehmann NE US soils')
```

## Vogel
```{r} 
plotGenerate(ISCN3, datasetName = 'Vogel')
```

## Myers-Smith
```{r} 
plotGenerate(ISCN3, datasetName = 'Myers-Smith')
```

## USGS Muhs
```{r} 
plotGenerate(ISCN3, datasetName = 'USGS Muhs')
```

## USGS Harden Yazoo
```{r} 
plotGenerate(ISCN3, datasetName = 'USGS Harden Yazoo')
```

## Boby_Mack
```{r} 
plotGenerate(ISCN3, datasetName = 'Boby_Mack')
```

## Kane
```{r} 
plotGenerate(ISCN3, datasetName = 'Kane')
```

## Bonanza LTER
```{r} 
plotGenerate(ISCN3, datasetName = 'Bonanza LTER')
```

## Jorgensen_YKDE
```{r} 
plotGenerate(ISCN3, datasetName = 'Jorgensen_YKDE')
```

## UMBS_FASET
```{r} 
plotGenerate(ISCN3, datasetName = 'UMBS_FASET')
```

## Jorgensen_ARCN
```{r} 
plotGenerate(ISCN3, datasetName = 'Jorgensen_ARCN')
```

## Oak Ridge National Lab_TDE
```{r} 
plotGenerate(ISCN3, datasetName = 'Oak Ridge National Lab_TDE')
```

## USGS Harden
```{r} 
plotGenerate(ISCN3, datasetName = 'USGS Harden')
```

## USDA-FS NRS Landscape Carbon Inventory
```{r} 
plotGenerate(ISCN3, datasetName = 'USDA-FS NRS Landscape Carbon Inventory')
```

## Bockheim
```{r} 
plotGenerate(ISCN3, datasetName = 'Bockheim')
```

## Jorgensen_NPS
```{r} 
plotGenerate(ISCN3, datasetName = 'Jorgensen_NPS')
```

## Permafrost_RCN
```{r} 
plotGenerate(ISCN3, datasetName = 'Permafrost_RCN')
```

## Northern Circumpolar Soil Carbon Database (NCSCD)
```{r} 
plotGenerate(ISCN3, datasetName = 'Northern Circumpolar Soil Carbon Database (NCSCD)')
```

## USGS_S3C
```{r} 
plotGenerate(ISCN3, datasetName = 'USGS_S3C')
```

## AK DSC Project SOC stock computation
```{r} 
plotGenerate(ISCN3, datasetName = 'AK DSC Project SOC stock computation')
```

## Worldwide soil carbon and nitrogen data
```{r} 
plotGenerate(ISCN3, datasetName = 'Worldwide soil carbon and nitrogen data')
```

## NRCS Sept/2014
```{r} 
plotGenerate(ISCN3, datasetName = 'NRCS Sept/2014')
```


## TODO

- Rename header and file name to reflect dataset_name
- Pull citation and add it to the bib file, check that citation matches the acknowledgement for study
- Check that the clean profile is correct given the orginal information
- Check that the clean layer is correct given the orginal information
- Check that maps are reasonable for the location
- Summerize what the modifications were for this particular dataset
- Create an issue on github with the template below
- Commit and link the commit to the issue

#### Github issue template

- [ ]  Evaluate dataset
- [ ]  Complete template checklist
- [ ]  Write up summary report narrative
- [ ]  Good commenting
- [ ]  External review by someone else

## Citations

Please see [bibtex citation here] for additional details and if you are using ISCN3 please cite.