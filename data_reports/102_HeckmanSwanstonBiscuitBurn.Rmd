# Heckman/Swanston Biscuit Burn

In this section, we will pull out the `Heckman/Swanston Biscuit Burn` from ISCN3 and clean it.
This dataset requires the country to be set to US.
We also remove the ISCN SOC stock computation, reducing the duplicated data entries.

```{r subset_HSBB}
## set the dataset name gotten from 
#unique(layer_raw$dataset_name_sub)
datasetName <- 'Heckman/Swanston Biscuit Burn'

## subset the citation and dataset description tables and merge them into a study table
dataset_study <- citation_raw %>% 
  filter(dataset_name == datasetName) %>% #pull out the info on the dataset we want here
  select(where(function(xx){!all(is.na(xx))})) %>% #pull out columns where values are not all "NA"
  full_join( #put the the citation and the dataset information together
    dataset_raw %>%
              filter(dataset_name == datasetName) %>% #subset the dataset table
              select(where(function(xx){!all(is.na(xx))})), #only pull columns that are not enitrely NA values
    suffix = c('_citation', '_dataset'))%>% #flag common columns that are not the id columns between the two tables
  standardCast() #go see index.Rmd for this function, mostly recasts the column to the right types
  
## subset the profile and dataset description tables and merge them into a study table
dataset_profile <- profile_raw  %>%
  filter(dataset_name_sub == datasetName) %>% #pull out the info on the dataset we want here
  mutate(`country (country)` = 'United States') %>% #hardcode country to correct one
  standardCast() %>% #recasting column to character type
  rename(dataset_name = 'dataset_name_sub') %>% #simplifying column name
  select(dataset_name, `site_name`, `profile_name`,
         `lat (dec. deg)`, `long (dec. deg)`, `datum (datum)`,
         `profile_zero_ref (profile_zero_ref)`,
         `state (state_province)`, `country (country)`, 
         `observation_date (YYYY-MM-DD)`, 
         `soil_series`,`ecoregion`, `surface_veg`,
         `elevation (m)`,  `aspect_deg (degree)`, `slope (percent)`) #selecting columns that will be used to create maps when called later
         
## subset the layer and dataset description tables and merge them into a study table
dataset_layer <- layer_raw %>%
  filter(dataset_name_sub == datasetName) %>% #pull out info for only this dataset
  mutate(`country (country)` = 'United States') %>% #hardcode country to correct one with desired format
  standardCast() %>% #run this through function standardCast()
  rename(dataset_name = 'dataset_name_sub') %>% #changing to more user-friendly name
  select(dataset_name, `site_name`, `profile_name`, layer_name,
         `lat (dec. deg)`, `long (dec. deg)`, 
         `layer_top (cm)`, `layer_bot (cm)`,
         `hzn`, `hzn_desgn`,
         `c_method`, `oc (percent)`, `13c (‰)`, `14c (‰)`) #select values to be included in later graphs/tables
  
all_study <- dataset_study
all_profile <- dataset_profile
all_layer <- dataset_layer
#setdiff(c(names(dataset_study), names(dataset_profile), names(dataset_layer)), unlist(type_cols))
```

## Tables

The 'r datasetName' is located in the Cascade Range in Oregon, USA, the top of the profile is the zero reference, profiles are drawn from one of six soil series', profiles are split between having mixed conifer/hardwood to no surface vegetation (see below).

```{r}
#dataset_study
dataset_profile %>% select_if(is.factor) %>% #pull data from profile of this dataset
  summary() %>% #produces result summary
  knitr::kable() #create a table of these values
```


```{r}
dataset_layer %>%
  pivot_longer(cols = intersect(names(.), type_cols$num_cols), values_drop_na = TRUE) %>%
  group_by(name) %>% summarize(n = length(value), unique_n = length(unique(value))) %>%
  bind_rows(
    dataset_layer %>%
      pivot_longer(cols = intersect(names(.), type_cols$factor_cols), values_drop_na = TRUE) %>%
      group_by(name) %>% summarize(n = length(value), unique_n = length(unique(value))) ) %>%
  arrange(n) %>%
  knitr::kable()
```

```{r viz_HSBB}
dataset_study
summary(dataset_profile %>% select_if(is.factor))
summary(dataset_layer %>% select_if(is.factor))
ggplot(data =  map_data('state') %>%
         full_join(dataset_profile %>% 
                     mutate(region = 
                              tolower(`state (state_province)`), by = 'region') %>%
                     group_by(region) %>% 
                     tally)) + 
  geom_polygon(aes(x=long, y = lat, group=group, fill = n), 
               color = 'black') +
  coord_fixed(1.3) + 
  theme_nothing() 
##using location data to plot sites on a state map
ggplot(data =  map_data('state') %>% #pull out relevant info, found in state column
         filter(region %in% c("oregon", "washington"))) + 
  geom_polygon(aes(x=long, y = lat, group = group), 
               fill = 'grey', color = 'black') + 
  geom_point(data=dataset_profile, 
             aes(x = `long (dec. deg)`, y = `lat (dec. deg)`),
             shape = 'x', color = 'red') +
  coord_fixed(1.3) +
  theme_nothing() 
dataset_layer %>%
  pivot_longer(cols = intersect(names(.), type_cols$num_cols), values_drop_na = TRUE) %>%
  group_by(name) %>% summarize(n = length(value), unique_n = length(unique(value))) %>%
  bind_rows(
    dataset_layer %>%
      pivot_longer(cols = intersect(names(.), type_cols$factor_cols), values_drop_na = TRUE) %>%
      group_by(name) %>% summarize(n = length(value), unique_n = length(unique(value))) ) %>%
  arrange(n) %>%
  knitr::kable()
ggplot(dataset_layer %>% 
         pivot_longer( cols=c('layer_top (cm)', 'layer_bot (cm)'),
                       values_to='depth') %>%
         pivot_longer(cols = c(`oc (percent)`,`13c (‰)`, `14c (‰)`), 
                      values_to = 'measurement', names_to = 'type')) +
  geom_line(aes(x=depth, y= measurement, group = profile_name)) +
  facet_wrap(~type, scales='free')
```
